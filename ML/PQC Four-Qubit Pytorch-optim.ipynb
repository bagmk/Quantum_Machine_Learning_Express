{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'qiskit-terra': '0.17.1', 'qiskit-aer': '0.8.1', 'qiskit-ignis': '0.6.0', 'qiskit-ibmq-provider': '0.12.2', 'qiskit-aqua': '0.9.1', 'qiskit': '0.25.1', 'qiskit-nature': None, 'qiskit-finance': None, 'qiskit-optimization': None, 'qiskit-machine-learning': None}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import qiskit\n",
    "qiskit.__qiskit_version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import Tensor\n",
    "from torch.nn import Linear, CrossEntropyLoss, MSELoss\n",
    "from torch.optim import LBFGS, SGD,Adam \n",
    "\n",
    "from qiskit  import Aer, QuantumCircuit\n",
    "from qiskit.utils import QuantumInstance\n",
    "from qiskit.opflow import AerPauliExpectation\n",
    "from qiskit.circuit import Parameter\n",
    "from qiskit.circuit.library import RealAmplitudes, ZZFeatureMap\n",
    "from qiskit_machine_learning.neural_networks import CircuitQNN, TwoLayerQNN\n",
    "from qiskit_machine_learning.connectors import TorchConnector\n",
    "\n",
    "qi = QuantumInstance(Aer.get_backend('statevector_simulator'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Test 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import pi\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "from torch.nn import (Module, Conv2d, Linear, Dropout2d, NLLLoss,\n",
    "                     MaxPool2d, Flatten, Sequential, ReLU)\n",
    "\n",
    "data0Path = r'../dataset/data3c.txt'\n",
    "data0Label = r'../dataset/data3clabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data0Path)\n",
    "dataLabels = np.loadtxt(data0Label)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.437796592712402\n",
      "13.855722427368164\n"
     ]
    }
   ],
   "source": [
    "from pandas.core.common import flatten\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=20)\n",
    "\n",
    "X= [np.array(list(flatten([data[j][0],data[j][0]]))) for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "num_inputs=4;\n",
    "\n",
    "feature_map = QuantumCircuit(4, name='Embed')\n",
    "feature_map.rx(Parameter('x[0]'),0)\n",
    "feature_map.rx(Parameter('x[1]'),1)\n",
    "feature_map.rx(Parameter('x[2]'),2)\n",
    "feature_map.rx(Parameter('x[3]'),3)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.ry(pi/4,2)\n",
    "feature_map.ry(pi/4,3)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "feature_map.rz(pi/4,2)\n",
    "feature_map.rz(pi/4,3)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(12):\n",
    "    param_y.append((Parameter('θ'+str(i))))\n",
    "ansatz = QuantumCircuit(4, name='PQC')\n",
    "for i in range(4):\n",
    "    ansatz.ry(param_y[i],i)\n",
    "for i in range(4):\n",
    "    ansatz.rz(param_y[i+4],i)\n",
    "ansatz.cx(0,1)\n",
    "ansatz.cx(2,3)\n",
    "ansatz.ry(param_y[8],1)\n",
    "ansatz.ry(param_y[9],2)\n",
    "ansatz.rz(param_y[10],1)\n",
    "ansatz.rz(param_y[11],2)\n",
    "ansatz.cx(1,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2\n",
    "output_shape = 2  \n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters(),lr=2,tolerance_grad=1e-09, tolerance_change=1e-11)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary(x):\n",
    "    return ('0'*(4-len('{:b}'.format(x) ))+'{:b}'.format(x))\n",
    "def firsttwo(x):\n",
    "    return x[:2]\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.45\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.contour.QuadContourSet at 0x28e85be9ca0>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=10)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j],X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data1a.txt'\n",
    "data1aLabel = r'../dataset/data1alabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X= [np.array(list(flatten([data[j][0],data[j][0]]))) for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "num_inputs=4;\n",
    "\n",
    "feature_map = QuantumCircuit(4, name='Embed')\n",
    "feature_map.rx(Parameter('x[0]'),0)\n",
    "feature_map.rx(Parameter('x[1]'),1)\n",
    "feature_map.rx(Parameter('x[2]'),2)\n",
    "feature_map.rx(Parameter('x[3]'),3)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.ry(pi/4,2)\n",
    "feature_map.ry(pi/4,3)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "feature_map.rz(pi/4,2)\n",
    "feature_map.rz(pi/4,3)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(12):\n",
    "    param_y.append((Parameter('θ'+str(i))))\n",
    "ansatz = QuantumCircuit(4, name='PQC')\n",
    "for i in range(4):\n",
    "    ansatz.ry(param_y[i],i)\n",
    "for i in range(4):\n",
    "    ansatz.rz(param_y[i+4],i)\n",
    "ansatz.cx(0,1)\n",
    "ansatz.cx(2,3)\n",
    "ansatz.ry(param_y[8],1)\n",
    "ansatz.ry(param_y[9],2)\n",
    "ansatz.rz(param_y[10],1)\n",
    "ansatz.rz(param_y[11],2)\n",
    "ansatz.cx(1,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2\n",
    "output_shape = 2  \n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.01,tolerance_grad=1e-09, tolerance_change=1e-11)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=5)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1bPath = r'../dataset/data1b.txt'\n",
    "data1bLabel = r'../dataset/data1blabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1bPath)\n",
    "dataLabels = np.loadtxt(data1bLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X= [np.array(list(flatten([data[j][0],data[j][0]]))) for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "num_inputs=4;\n",
    "\n",
    "feature_map = QuantumCircuit(4, name='Embed')\n",
    "feature_map.rx(Parameter('x[0]'),0)\n",
    "feature_map.rx(Parameter('x[1]'),1)\n",
    "feature_map.rx(Parameter('x[2]'),2)\n",
    "feature_map.rx(Parameter('x[3]'),3)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.ry(pi/4,2)\n",
    "feature_map.ry(pi/4,3)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "feature_map.rz(pi/4,2)\n",
    "feature_map.rz(pi/4,3)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(12):\n",
    "    param_y.append((Parameter('θ'+str(i))))\n",
    "ansatz = QuantumCircuit(4, name='PQC')\n",
    "for i in range(4):\n",
    "    ansatz.ry(param_y[i],i)\n",
    "for i in range(4):\n",
    "    ansatz.rz(param_y[i+4],i)\n",
    "ansatz.cx(0,1)\n",
    "ansatz.cx(2,3)\n",
    "ansatz.ry(param_y[8],1)\n",
    "ansatz.ry(param_y[9],2)\n",
    "ansatz.rz(param_y[10],1)\n",
    "ansatz.rz(param_y[11],2)\n",
    "ansatz.cx(1,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2\n",
    "output_shape = 2  \n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.01,tolerance_grad=1e-09, tolerance_change=1e-11)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=10)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j],X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data1c.txt'\n",
    "data1aLabel = r'../dataset/data1clabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X= [np.array(list(flatten([data[j][0],data[j][0]]))) for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "num_inputs=4;\n",
    "\n",
    "feature_map = QuantumCircuit(4, name='Embed')\n",
    "feature_map.rx(Parameter('x[0]'),0)\n",
    "feature_map.rx(Parameter('x[1]'),1)\n",
    "feature_map.rx(Parameter('x[2]'),2)\n",
    "feature_map.rx(Parameter('x[3]'),3)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.ry(pi/4,2)\n",
    "feature_map.ry(pi/4,3)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "feature_map.rz(pi/4,2)\n",
    "feature_map.rz(pi/4,3)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(12):\n",
    "    param_y.append((Parameter('θ'+str(i))))\n",
    "ansatz = QuantumCircuit(4, name='PQC')\n",
    "for i in range(4):\n",
    "    ansatz.ry(param_y[i],i)\n",
    "for i in range(4):\n",
    "    ansatz.rz(param_y[i+4],i)\n",
    "ansatz.cx(0,1)\n",
    "ansatz.cx(2,3)\n",
    "ansatz.ry(param_y[8],1)\n",
    "ansatz.ry(param_y[9],2)\n",
    "ansatz.rz(param_y[10],1)\n",
    "ansatz.rz(param_y[11],2)\n",
    "ansatz.cx(1,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2\n",
    "output_shape = 2  \n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.01,tolerance_grad=1e-09, tolerance_change=1e-11)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=10)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j],X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data2a.txt'\n",
    "data1aLabel = r'../dataset/data2alabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X= [np.array(list(flatten([data[j][0],data[j][0]]))) for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "num_inputs=4;\n",
    "\n",
    "feature_map = QuantumCircuit(4, name='Embed')\n",
    "feature_map.rx(Parameter('x[0]'),0)\n",
    "feature_map.rx(Parameter('x[1]'),1)\n",
    "feature_map.rx(Parameter('x[2]'),2)\n",
    "feature_map.rx(Parameter('x[3]'),3)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.ry(pi/4,2)\n",
    "feature_map.ry(pi/4,3)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "feature_map.rz(pi/4,2)\n",
    "feature_map.rz(pi/4,3)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(12):\n",
    "    param_y.append((Parameter('θ'+str(i))))\n",
    "ansatz = QuantumCircuit(4, name='PQC')\n",
    "for i in range(4):\n",
    "    ansatz.ry(param_y[i],i)\n",
    "for i in range(4):\n",
    "    ansatz.rz(param_y[i+4],i)\n",
    "ansatz.cx(0,1)\n",
    "ansatz.cx(2,3)\n",
    "ansatz.ry(param_y[8],1)\n",
    "ansatz.ry(param_y[9],2)\n",
    "ansatz.rz(param_y[10],1)\n",
    "ansatz.rz(param_y[11],2)\n",
    "ansatz.cx(1,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2\n",
    "output_shape = 2  \n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.01,tolerance_grad=1e-09, tolerance_change=1e-11)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=10)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j],X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data2b.txt'\n",
    "data1aLabel = r'../dataset/data2blabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X= [np.array(list(flatten([data[j][0],data[j][0]]))) for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "num_inputs=4;\n",
    "\n",
    "feature_map = QuantumCircuit(4, name='Embed')\n",
    "feature_map.rx(Parameter('x[0]'),0)\n",
    "feature_map.rx(Parameter('x[1]'),1)\n",
    "feature_map.rx(Parameter('x[2]'),2)\n",
    "feature_map.rx(Parameter('x[3]'),3)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.ry(pi/4,2)\n",
    "feature_map.ry(pi/4,3)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "feature_map.rz(pi/4,2)\n",
    "feature_map.rz(pi/4,3)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(12):\n",
    "    param_y.append((Parameter('θ'+str(i))))\n",
    "ansatz = QuantumCircuit(4, name='PQC')\n",
    "for i in range(4):\n",
    "    ansatz.ry(param_y[i],i)\n",
    "for i in range(4):\n",
    "    ansatz.rz(param_y[i+4],i)\n",
    "ansatz.cx(0,1)\n",
    "ansatz.cx(2,3)\n",
    "ansatz.ry(param_y[8],1)\n",
    "ansatz.ry(param_y[9],2)\n",
    "ansatz.rz(param_y[10],1)\n",
    "ansatz.rz(param_y[11],2)\n",
    "ansatz.cx(1,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2\n",
    "output_shape = 2  \n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.01,tolerance_grad=1e-09, tolerance_change=1e-11)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=10)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j],X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data2c.txt'\n",
    "data1aLabel = r'../dataset/data2clabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X= [np.array(list(flatten([data[j][0],data[j][0]]))) for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "num_inputs=4;\n",
    "\n",
    "feature_map = QuantumCircuit(4, name='Embed')\n",
    "feature_map.rx(Parameter('x[0]'),0)\n",
    "feature_map.rx(Parameter('x[1]'),1)\n",
    "feature_map.rx(Parameter('x[2]'),2)\n",
    "feature_map.rx(Parameter('x[3]'),3)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.ry(pi/4,2)\n",
    "feature_map.ry(pi/4,3)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "feature_map.rz(pi/4,2)\n",
    "feature_map.rz(pi/4,3)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(12):\n",
    "    param_y.append((Parameter('θ'+str(i))))\n",
    "ansatz = QuantumCircuit(4, name='PQC')\n",
    "for i in range(4):\n",
    "    ansatz.ry(param_y[i],i)\n",
    "for i in range(4):\n",
    "    ansatz.rz(param_y[i+4],i)\n",
    "ansatz.cx(0,1)\n",
    "ansatz.cx(2,3)\n",
    "ansatz.ry(param_y[8],1)\n",
    "ansatz.ry(param_y[9],2)\n",
    "ansatz.rz(param_y[10],1)\n",
    "ansatz.rz(param_y[11],2)\n",
    "ansatz.cx(1,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2\n",
    "output_shape = 2  \n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.01,tolerance_grad=1e-09, tolerance_change=1e-11)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=10)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j],X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data3a.txt'\n",
    "data1aLabel = r'../dataset/data3alabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X= [np.array(list(flatten([data[j][0],data[j][0]]))) for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "num_inputs=4;\n",
    "\n",
    "feature_map = QuantumCircuit(4, name='Embed')\n",
    "feature_map.rx(Parameter('x[0]'),0)\n",
    "feature_map.rx(Parameter('x[1]'),1)\n",
    "feature_map.rx(Parameter('x[2]'),2)\n",
    "feature_map.rx(Parameter('x[3]'),3)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.ry(pi/4,2)\n",
    "feature_map.ry(pi/4,3)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "feature_map.rz(pi/4,2)\n",
    "feature_map.rz(pi/4,3)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(12):\n",
    "    param_y.append((Parameter('θ'+str(i))))\n",
    "ansatz = QuantumCircuit(4, name='PQC')\n",
    "for i in range(4):\n",
    "    ansatz.ry(param_y[i],i)\n",
    "for i in range(4):\n",
    "    ansatz.rz(param_y[i+4],i)\n",
    "ansatz.cx(0,1)\n",
    "ansatz.cx(2,3)\n",
    "ansatz.ry(param_y[8],1)\n",
    "ansatz.ry(param_y[9],2)\n",
    "ansatz.rz(param_y[10],1)\n",
    "ansatz.rz(param_y[11],2)\n",
    "ansatz.cx(1,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2\n",
    "output_shape = 2  \n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.01,tolerance_grad=1e-09, tolerance_change=1e-11)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=10)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j],X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data3b.txt'\n",
    "data1aLabel = r'../dataset/data3blabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X= [np.array(list(flatten([data[j][0],data[j][0]]))) for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "num_inputs=4;\n",
    "\n",
    "feature_map = QuantumCircuit(4, name='Embed')\n",
    "feature_map.rx(Parameter('x[0]'),0)\n",
    "feature_map.rx(Parameter('x[1]'),1)\n",
    "feature_map.rx(Parameter('x[2]'),2)\n",
    "feature_map.rx(Parameter('x[3]'),3)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.ry(pi/4,2)\n",
    "feature_map.ry(pi/4,3)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "feature_map.rz(pi/4,2)\n",
    "feature_map.rz(pi/4,3)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(12):\n",
    "    param_y.append((Parameter('θ'+str(i))))\n",
    "ansatz = QuantumCircuit(4, name='PQC')\n",
    "for i in range(4):\n",
    "    ansatz.ry(param_y[i],i)\n",
    "for i in range(4):\n",
    "    ansatz.rz(param_y[i+4],i)\n",
    "ansatz.cx(0,1)\n",
    "ansatz.cx(2,3)\n",
    "ansatz.ry(param_y[8],1)\n",
    "ansatz.ry(param_y[9],2)\n",
    "ansatz.rz(param_y[10],1)\n",
    "ansatz.rz(param_y[11],2)\n",
    "ansatz.cx(1,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2\n",
    "output_shape = 2  \n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.01,tolerance_grad=1e-09, tolerance_change=1e-11)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=10)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j],X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data 3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1aPath = r'../dataset/data3c.txt'\n",
    "data1aLabel = r'../dataset/data3clabel.txt'\n",
    "\n",
    "dataCoords = np.loadtxt(data1aPath)\n",
    "dataLabels = np.loadtxt(data1aLabel)\n",
    "\n",
    "# Make a data structure which is easier to work with\n",
    "# for shuffling. \n",
    "# Also, notice we change the data labels from {0, 1} to {-1, +1}\n",
    "data = list(zip(dataCoords, 2*dataLabels-1))\n",
    "shuffled_data = shuffle(data)\n",
    "\n",
    "\n",
    "np.random.seed(2)\n",
    "#data_ixs = np.random.choice(len(shuffled_data), size=len(shuffled_data))\n",
    "data_ixs = np.random.choice(len(data), size=100)\n",
    "\n",
    "X= [np.array(list(flatten([data[j][0],data[j][0]]))) for j in data_ixs]\n",
    "y = [data[j][1] for j in data_ixs]\n",
    "y01 =  [ (x + 1)/2 for x in y]\n",
    "X_ = Tensor(X)\n",
    "y_ = Tensor(y).reshape(len(y), 1)\n",
    "y01_ = Tensor(y01).reshape(len(y)).long()\n",
    "\n",
    "num_inputs=4;\n",
    "\n",
    "feature_map = QuantumCircuit(4, name='Embed')\n",
    "feature_map.rx(Parameter('x[0]'),0)\n",
    "feature_map.rx(Parameter('x[1]'),1)\n",
    "feature_map.rx(Parameter('x[2]'),2)\n",
    "feature_map.rx(Parameter('x[3]'),3)\n",
    "feature_map.ry(pi/4,0)\n",
    "feature_map.ry(pi/4,1)\n",
    "feature_map.ry(pi/4,2)\n",
    "feature_map.ry(pi/4,3)\n",
    "feature_map.rz(pi/4,0)\n",
    "feature_map.rz(pi/4,1)\n",
    "feature_map.rz(pi/4,2)\n",
    "feature_map.rz(pi/4,3)\n",
    "\n",
    "\n",
    "param_y=[];\n",
    "for i in range(12):\n",
    "    param_y.append((Parameter('θ'+str(i))))\n",
    "ansatz = QuantumCircuit(4, name='PQC')\n",
    "for i in range(4):\n",
    "    ansatz.ry(param_y[i],i)\n",
    "for i in range(4):\n",
    "    ansatz.rz(param_y[i+4],i)\n",
    "ansatz.cx(0,1)\n",
    "ansatz.cx(2,3)\n",
    "ansatz.ry(param_y[8],1)\n",
    "ansatz.ry(param_y[9],2)\n",
    "ansatz.rz(param_y[10],1)\n",
    "ansatz.rz(param_y[11],2)\n",
    "ansatz.cx(1,2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "qc = QuantumCircuit(num_inputs)\n",
    "qc.append(feature_map, range(num_inputs))\n",
    "qc.append(ansatz, range(num_inputs))\n",
    "\n",
    "parity = lambda x: firsttwo(binary(x)).count('1') % 2\n",
    "output_shape = 2  \n",
    "\n",
    "qnn2 = CircuitQNN(qc, input_params=feature_map.parameters, weight_params=ansatz.parameters, \n",
    "                  interpret=parity, output_shape=output_shape, quantum_instance=qi)\n",
    "\n",
    "# set up PyTorch module\n",
    "initial_weights = 0.1*(2*np.random.rand(qnn2.num_weights) - 1)\n",
    "model2 = TorchConnector(qnn2, initial_weights)\n",
    "\n",
    "\n",
    "# define model, optimizer, and loss\n",
    "optimizer = LBFGS(model2.parameters(),lr=0.01,tolerance_grad=1e-09, tolerance_change=1e-11)\n",
    "f_loss = CrossEntropyLoss()\n",
    "\n",
    "# start training\n",
    "model2.train()    \n",
    "def closure():\n",
    "    optimizer.zero_grad()                  # initialize gradient\n",
    "    \n",
    "    loss = 0.0                                             # initialize loss    \n",
    "    for x, y_target in zip(X, y01):                        # evaluate batch loss\n",
    "        output = model2(Tensor(x)).reshape(1, 2)           # forward pass\n",
    "        loss += f_loss(output, Tensor([y_target]).long())  # calculate loss\n",
    "        \n",
    "    loss.backward()                                        # backward pass\n",
    "    \n",
    "    print(loss.item())                                     # print loss\n",
    "    return loss\n",
    "\n",
    "# run optimizer (LBFGS requires closure)\n",
    "optimizer.step(closure);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model and compute accuracy\n",
    "y_predict = []\n",
    "for x in X:\n",
    "    output = model2(Tensor(x))\n",
    "    y_predict += [np.argmax(output.detach().numpy())]\n",
    "\n",
    "print('Accuracy:', sum(y_predict == np.array(y01))/len(np.array(y01)))\n",
    "\n",
    "# plot results\n",
    "# red == wrongly classified\n",
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "    if y_target != y_:\n",
    "        plt.scatter(x[0], x[1], s=200, facecolors='none', edgecolors='r', linewidths=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y_target, y_ in zip(X, y01, y_predict):\n",
    "    if y_target == 1:\n",
    "        plt.plot(x[0], x[1], 'bo')\n",
    "    else:\n",
    "        plt.plot(x[0], x[1], 'go')\n",
    "\n",
    "X1 = np.linspace(0, 1, num=10)\n",
    "Z1 = np.zeros((len(X1), len(X1)))\n",
    "\n",
    "# Contour map\n",
    "for j in range(len(X1)):\n",
    "    for k in range(len(X1)):\n",
    "        # Fill Z with the labels (numerical values)\n",
    "        # the inner loop goes over the columns of Z,\n",
    "        # which corresponds to sweeping x-values\n",
    "        # Therefore, the role of j,k is flipped in the signature\n",
    "        Z1[j, k] = np.argmax(model2(Tensor([X1[k],X1[j],X1[k],X1[j]])).detach().numpy())\n",
    "        \n",
    "plt.contourf(X1, X1, Z1, cmap='bwr', levels=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
